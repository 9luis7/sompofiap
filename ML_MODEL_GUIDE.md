# ü§ñ Guia do Sistema de Modelos ML - Formato Joblib/Pickle

Sistema completo para trabalhar com modelos de Machine Learning salvos em **joblib** ou **pickle**.

---

## üìã Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ dados_acidentes.xlsx     ‚îÇ
‚îÇ (47K acidentes DATATRAN) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ train_risk_model.py      ‚îÇ
‚îÇ - Treina modelo LightGBM ‚îÇ
‚îÇ - Salva em joblib        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚îÇ                                  ‚îÇ
             ‚ñº                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ risk_model.joblib        ‚îÇ    ‚îÇ risk_scores.json          ‚îÇ
‚îÇ (Modelo ML treinado)     ‚îÇ    ‚îÇ (Scores pr√©-calculados)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                              ‚îÇ
             ‚ñº                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ ml_prediction_api.py     ‚îÇ               ‚îÇ
‚îÇ Flask API (porta 5000)   ‚îÇ               ‚îÇ
‚îÇ - Carrega modelo joblib  ‚îÇ               ‚îÇ
‚îÇ - Predi√ß√µes em tempo real‚îÇ               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
             ‚îÇ                              ‚îÇ
             ‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ        ‚îÇ
             ‚ñº        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Backend TypeScript (porta 3001)          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ ml-api-client.service.ts             ‚îÇ ‚îÇ
‚îÇ ‚îÇ - Chama API Python (ML em tempo real)‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ risk-lookup.service.ts               ‚îÇ ‚îÇ
‚îÇ ‚îÇ - Usa scores pr√©-calculados (fallback)‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ Guia de In√≠cio R√°pido

### Passo 1: Treinar e Salvar Modelo

```bash
# Treina o modelo e salva em backend/models/
python train_risk_model.py
```

**Arquivos gerados:**

- `backend/models/risk_model.joblib` - Modelo LightGBM treinado
- `backend/models/label_encoders.joblib` - Encoders de features categ√≥ricas
- `backend/risk_scores.json` - Scores pr√©-calculados (cache/fallback)

### Passo 2: Iniciar API Python (opcional)

```bash
# Terminal 1: API Python de ML
python ml_prediction_api.py

# Ou no Windows:
start_ml_api.bat
```

API dispon√≠vel em: `http://localhost:5000`

### Passo 3: Iniciar Backend TypeScript

```bash
# Terminal 2: Backend Node.js
cd backend
npm run build
npm start
```

Backend dispon√≠vel em: `http://localhost:3001`

---

## üîÑ Dois Modos de Opera√ß√£o

### Modo 1: Scores Pr√©-calculados (Padr√£o)

**Vantagens:**

- ‚ö° Ultra r√°pido (~1ms)
- üì¶ Sem depend√™ncia da API Python
- üíæ Baixo uso de mem√≥ria
- ‚úÖ Sempre dispon√≠vel

**Como usar:**

```bash
curl -X POST http://localhost:3001/api/v1/risk/predict \
  -H "Content-Type: application/json" \
  -d '{"uf":"SP", "br":"116", "km":523}'
```

### Modo 2: ML em Tempo Real

**Vantagens:**

- üéØ Predi√ß√µes mais precisas
- üß† Usa modelo treinado diretamente
- üîÑ Sem necessidade de pr√©-calcular
- üìä Probabilidades detalhadas

**Como usar:**

```bash
curl -X POST http://localhost:3001/api/v1/risk/predict \
  -H "Content-Type: application/json" \
  -d '{
    "uf":"SP",
    "br":"116",
    "km":523,
    "hour":22,
    "weatherCondition":"chuva",
    "useRealTimeML": true
  }'
```

---

## üì° API Endpoints

### Backend TypeScript (porta 3001)

#### 1. Status do Sistema

```http
GET /api/v1/risk/status
```

Retorna status de ambos os modos (pr√©-calculado e ML tempo real).

#### 2. Predi√ß√£o de Risco

```http
POST /api/v1/risk/predict

Body:
{
  "uf": "SP",
  "br": "116",
  "km": 523,
  "hour": 14,
  "dayOfWeek": 2,
  "month": 10,
  "weatherCondition": "chuva",
  "dayPhase": "dia",
  "roadType": "simples",
  "useRealTimeML": true  // false = usa scores pr√©-calculados
}
```

### API Python Flask (porta 5000)

#### 1. Health Check

```http
GET /health
```

#### 2. Informa√ß√µes do Modelo

```http
GET /model-info
```

#### 3. Predi√ß√£o Direta

```http
POST /predict

Body:
{
  "uf": "SP",
  "br": 116,
  "km": 523.5,
  "hour": 14,
  "dayOfWeek": 2,
  "month": 10,
  "weatherCondition": "claro",
  "dayPhase": "dia",
  "roadType": "simples"
}
```

#### 4. Predi√ß√£o em Lote

```http
POST /predict-batch

Body:
{
  "predictions": [
    {"uf": "SP", "br": 116, "km": 100, ...},
    {"uf": "SP", "br": 116, "km": 200, ...}
  ]
}
```

---

## üîß Trabalhando com Modelos

### Salvar Modelo Customizado

```python
import joblib
import lightgbm as lgb

# Treinar seu modelo
model = lgb.LGBMClassifier(...)
model.fit(X_train, y_train)

# Salvar em joblib (recomendado)
joblib.dump(model, 'backend/models/risk_model.joblib')

# Ou em pickle (alternativa)
import pickle
with open('backend/models/risk_model.pkl', 'wb') as f:
    pickle.dump(model, f)
```

### Carregar Modelo

```python
import joblib

# Carregar de joblib
model = joblib.load('backend/models/risk_model.joblib')

# Ou de pickle
import pickle
with open('backend/models/risk_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Fazer predi√ß√£o
prediction = model.predict(X_new)
```

### Atualizar Modelo no Sistema

1. **Treinar novo modelo** e salvar em `backend/models/risk_model.joblib`
2. **Reiniciar API Python**: O modelo ser√° recarregado automaticamente
3. **N√£o precisa** reiniciar o backend TypeScript

```bash
# Treinar novo modelo
python train_risk_model.py

# Reiniciar apenas API Python (se estiver rodando)
# Ctrl+C e depois:
python ml_prediction_api.py
```

---

## üìä Formatos Suportados

### Joblib (Recomendado)

```python
import joblib

# Salvar
joblib.dump(model, 'model.joblib')

# Carregar
model = joblib.load('model.joblib')
```

**Vantagens:**

- ‚úÖ Mais eficiente para arrays NumPy
- ‚úÖ Melhor compress√£o
- ‚úÖ Padr√£o scikit-learn

### Pickle

```python
import pickle

# Salvar
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

# Carregar
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)
```

**Vantagens:**

- ‚úÖ Biblioteca padr√£o Python
- ‚úÖ Funciona com qualquer objeto Python

---

## üîê Boas Pr√°ticas

### 1. Versionamento de Modelos

```bash
backend/models/
‚îú‚îÄ‚îÄ risk_model_v1.0.0.joblib
‚îú‚îÄ‚îÄ risk_model_v1.1.0.joblib
‚îú‚îÄ‚îÄ risk_model_latest.joblib -> risk_model_v1.1.0.joblib
‚îî‚îÄ‚îÄ label_encoders_v1.1.0.joblib
```

### 2. Metadados do Modelo

Salvar junto com o modelo:

```python
import joblib
from datetime import datetime

model_metadata = {
    'model': model,
    'version': '1.1.0',
    'trained_at': datetime.now().isoformat(),
    'accuracy': 0.7718,
    'features': feature_names,
    'encoders': label_encoders
}

joblib.dump(model_metadata, 'risk_model_with_metadata.joblib')
```

### 3. Valida√ß√£o de Modelo

```python
import joblib

# Carregar
data = joblib.load('model.joblib')

# Verificar estrutura
if isinstance(data, dict):
    model = data['model']
    version = data['version']
    print(f"Modelo vers√£o {version} carregado")
else:
    model = data
    print("Modelo carregado (sem metadados)")
```

---

## üß™ Testes

### Testar Modelo Localmente (Python)

```python
import joblib
import numpy as np

# Carregar modelo
model = joblib.load('backend/models/risk_model.joblib')
encoders = joblib.load('backend/models/label_encoders.joblib')

# Preparar features de teste
test_features = np.array([[
    encoders['uf'].transform(['SP'])[0],  # uf_encoded
    116,  # br
    523,  # km
    14,   # hora
    2,    # dia_semana
    10,   # mes
    encoders['clima_categoria'].transform(['claro'])[0],
    encoders['fase_dia_categoria'].transform(['dia'])[0],
    encoders['tipo_pista_categoria'].transform(['simples'])[0]
]])

# Predi√ß√£o
prediction = model.predict(test_features)
probabilities = model.predict_proba(test_features)

print(f"Classe predita: {prediction[0]}")
print(f"Probabilidades: {probabilities[0]}")
```

### Testar API Python

```bash
# Health check
curl http://localhost:5000/health

# Predi√ß√£o
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"uf":"SP","br":116,"km":523}'
```

### Testar Backend Completo

```bash
# Status (mostra ambos os modos)
curl http://localhost:3001/api/v1/risk/status

# Predi√ß√£o com scores pr√©-calculados
curl -X POST http://localhost:3001/api/v1/risk/predict \
  -H "Content-Type: application/json" \
  -d '{"uf":"SP","br":"116","km":523}'

# Predi√ß√£o com ML em tempo real
curl -X POST http://localhost:3001/api/v1/risk/predict \
  -H "Content-Type: application/json" \
  -d '{"uf":"SP","br":"116","km":523,"useRealTimeML":true}'
```

---

## üìù Troubleshooting

### Modelo n√£o carrega

```bash
# Verificar se arquivo existe
ls backend/models/risk_model.joblib

# Se n√£o existir, treinar
python train_risk_model.py
```

### API Python n√£o inicia

```bash
# Instalar depend√™ncias
pip install -r requirements-ml.txt

# Verificar porta 5000 n√£o est√° em uso
netstat -an | findstr ":5000"
```

### Backend n√£o conecta √† API Python

```bash
# Verificar se API Python est√° rodando
curl http://localhost:5000/health

# Se n√£o estiver, iniciar
python ml_prediction_api.py
```

---

## üéØ Performance

### Compara√ß√£o de Modos

| Modo                  | Lat√™ncia | Precis√£o   | Mem√≥ria            | Depend√™ncias    |
| --------------------- | -------- | ---------- | ------------------ | --------------- |
| Scores Pr√©-calculados | ~1ms     | Alta       | ~2MB               | Nenhuma         |
| ML Tempo Real         | ~10-50ms | Muito Alta | ~50MB (API Python) | Flask, LightGBM |

### Recomenda√ß√µes

- **Produ√ß√£o com alto volume**: Use scores pr√©-calculados
- **Casos espec√≠ficos/raros**: Use ML tempo real
- **H√≠brido**: Use pr√©-calculados como cache, ML tempo real para fallback

---

## üöÄ Deploy

### Op√ß√£o 1: Apenas Backend TypeScript

```bash
# Copiar risk_scores.json para produ√ß√£o
# Backend funciona sem API Python
npm run build
npm start
```

### Op√ß√£o 2: Backend + API Python

```bash
# Terminal 1: API Python
python ml_prediction_api.py

# Terminal 2: Backend TypeScript
cd backend
npm run build
npm start
```

### Docker (futuro)

```dockerfile
# Exemplo de Dockerfile para API Python
FROM python:3.11-slim
WORKDIR /app
COPY requirements-ml.txt .
RUN pip install -r requirements-ml.txt
COPY ml_prediction_api.py .
COPY backend/models/ backend/models/
CMD ["python", "ml_prediction_api.py"]
```

---

**Sistema desenvolvido por Sompo - 2025**
**Suporte a Modelos: Joblib, Pickle**
